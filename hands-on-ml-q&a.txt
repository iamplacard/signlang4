Chapter 1. Q&A
1. 머신러닝을 어떻게 정의할 수 있나요?
   A : 데이터로 부터 학습하여 정답을 찾아 가는 것을 프로그램밍하는 것
2. 머신러닝이 도움을 줄 수 있는 문제 유형 네 가지를 말해 보세요.
   A : 문제가 단순하지 않고 규칙이 점점 복잡해 지는 분야 / 기존 솔루션으로는 마노은 수동 조정과 규칙이 필요한 문제
       전통적인 방식으로는 너무 복잡하거나 알려진 알고리즘이 없는 분야 (음성인식)
       유동적인 환경
       복잡한 문제와 대량의 데이터에서 통찰 얻기
3. 레이블된 훈련 세트란 무엇인가?
   A : 스팸 분류와 같이 Supervized learning 에서 훈련하는 세트에 레이블을 붙여서 훈련하는 방법
4. 가장 널리 사용되는 지도학습 작업 두 가지는 무엇인가요?
   A : 분류 - classification 과 회귀 - Regression (선형 회귀 / 로지스틱 회귀)
5. 보편적인 비 지도 학습 네 가지는 무엇입니까? - 알고리즘
   A : 계층 군집 (Hierarchical clustering) / 시각화 (Visualization) - 차원 축소 (dimensionality reduction) / 
   이상치 탐지 (abnormaly detection) / 연관 규칙 학습 (association rule learning) 
6. 사전 정보가 없는 여러 지형에서 로봇을 걸어가게 하려면 어떤 종류의 머신러닝 알고리즘을 사용할 수 있나요?
   A : 강화 학습(Reinforcement Learning) 을 사용합니다. 에이전트(Agent)라는 것을 이용해서 환경(Environment)을 관찰해서 행동(Action)을 수행하고 
   그 결과로 보상(Reward)을 또는 벌점(Penalty)을 받는 방법으로 정책(Policy)이라는 전략을 학습하는 것을 말합니다. - 보행 로봇 / 알파고가 좋은 예..
7. 고객을 여러 그룹으로 분할 하려면 어떤 알고리즘을 사용해야 하나요?
   A : 계층 군집 (Hierarchical culstering)  을 사용하면 각 그룹을 작은 그룹으로 세분화 할 수 있습니다.
8. 스팸 감지 문제는 지도학습과 비지도 학습 중 어떤 문제로 볼 수 있나요?
   A : 분류 알고 리즘을 사용하는 지도학습(Supervized Learning)이라고 볼 수 있다.
9. 온라인 학습 시스템이 무엇인가요?
   A : 데이터를 순차적으로 한 개씩 또는 미니 배치(mini batch)라 부르는 작은 무끔 다누이로 주입하여 시스템을 훈련 시키는 것으로 연속적으로 데이터를 
   받고 빠른 변화에 스스로 적응해야 하는 시스템에 적합하며, 주식 예측이나 컴퓨팅 자원이 제한된 경웨 좋은 알고리즘.
10.외부 메모리 학습이 무엇인가요? 
   A : 텀퓨터 한대의 메인 메모리에 들어 갈 수 없는 아주 큰 데이터셋을 학습한ㄴ 시스템에도 온라인 학습 알고리즘을 사용할 수 있는 데 이를 외부 
   메모리(out-of-core)학습이라고 함.
11.예측을 하기 위해 유사도 측정에 의존하는 학습 알고리즘은 무엇인가요?
   A : instance-based learning( 사례 기반 학습)으로 시스템이 사례를 기억함으로써 학습하는 것으로 가장 간단한 형태의 학스이며 단순히 기억하여 
   동일한 것을 찾아 분류 하는 알고리즘 입니다. 이렇게 하기 위해서는 유사도를 측정하여 새로운 데이터를 일반화 합니다. 
12.모델 파라미터와 학습 알고리즘의 하이퍼파라미터 사이에는 어떤 차이가 있나요?
   A : 사례기반 학습에 대비하여 모델 기반 학습은 샘플로 부터 모델을 만들어 예측에 사용하는 것을 말합니다. 특정한 샘플들을 일반화 시키기 위해 
   사용하는 방법으로 선형 모델을 사용하는 데 샘플을 일반화 시킨 선형 모델은 선형 방정식 y = a + bx 의 형태로 나와서 'x' 의 변수에 값을 넣으면
   y 가 예측이 되도록 합니다. 이 때 a,b 를 모델 파라미터로 사용하고 있으며 이런 예측 모델이 최상의 성능을 내도록 하는 값을 만드는 것이 
   이 모델 파라미터 a,b 를 정하는 것이고 이 값을 최적화 하는 알고리즘이 선형 회귀입니다. 선형 모델에서 모델을 단순화하면서 과대적합의 
   요소(훈현 데이터에 있는 잡음의 양에 비해 모델이 너무 복잡할 때 일어 납니다.)가 발생을 하게 되는데.. 이러한 과대 적합의 위험을 감소 시키기 
   위해 모델에 제약을 가하는 것을 규제(Regularization) 이라고 하고 학습 하는 동안 적용할 규제의 양은 모델이 아닌 학습 알고리즘의 파라미터인 
   하이퍼 파라미터 (hyperparameter)가 결정합니다. 학습 알고리즘으로 부터 영향을 받지 않으며, 훈련 전에 미리 지정되고, 훈련하는 동안에는 
   상수로 남아 있다. 과대 적합을 대응하는 요소이다. 
13.모델 기반 알고리즘이 찾는 것은 무엇인가요? 성공을 위해 이 알고리즘이 사용하는 가장 일반적인 전략은 무엇인가요? 예측은 어떻게 만드나요?
   A : 모델 기반 학습은 샘플로 부터 모델을 만들어 예측에 사용하는 것을 말합니다. 특정한 샘플들을 일반화 시키기 위해 
   사용하는 방법으로 선형 모델을 사용하는 데 샘플을 일반화 시킨 선형 모델은 선형 방정식 y = a + bx 의 형태로 나와서 'x' 의 변수에 값을 넣으면
   y 가 예측이 되도록 합니다. 이 때 a,b 를 모델 파라미터로 사용하고 있으며 이런 예측 모델이 최상의 성능을 내도록 하는 값을 만드는 것이 
   이 모델 파라미터 a,b 를 정하는 것이고 이 값을 최적화 하는 알고리즘이 선형 회귀입니다.
14.머신러닝의 주요 도전 과제는 무엇인가요?
   A : 머신 러닝 훈련 세트가 너무 작거나, 대표성이 없는 데이터 이거나, 잡음이 많고 관련 없는 특성을 지닌 데이터는 아니어야 하고, 모델이 
   너무 단순화 되어 있거나 너무 복잡화 (과소 적합이나 / 과대 적합)되어 잇지 않아야 하는 과제를 앉고 있다.
15.모델이 훈련 데이터에서의 성능은 좋지만 새로운 샘플에서의 일반화 성능이 나쁘다면 어떤 문제가 있는 건가요? 가능한 해결책 세 가지는 무엇인가요?
   A : 이런 경우가 훈련 데이터에는 너무 잘 맞지만 일반성이 떨오지는 것으로 과대 적합이라고 말할 수 있는 데.. 이에 대한 대응책으로는 
       잡음을 제거하고, 데이터 새트를 늘이고 모델에 제약을 가하는 것이 필요하다. 
       
       반대로 모델이 너무 단순해서 데이터네 내재된 구조를 학습하지 못하는 경우가 과소 적합인데 이에 대한 해결 책은 1) 모델 파라미터가 더 많은 
       강력한 모델을 선택 2) 학습 알고리즘에 더 좋은 특성을 제공 3) 모델의 제약을 줄이기가 필요하다.        
16.테스트 세트가 무엇이고 왜 사용해야 하나요?
   A : 모델이 새로운 샘플에 얼마나 잘 일반화 될지 아는 유링한 방법이 새로운 샘플에 실제로 적용해 보는 것이 있는 데.. 이러한 테스트를 위해 
       가지고 있는 테스트 데이터를 테스트 세트라고 하며 새로운 샘플에 대한 오류 비율 (일반화 오차)에 대한 추정 값을 얻고자 하는 데 사용되며 
       이 추정값이 새로운 샘플에 모델이 얼마나 잘 작동할 지 알려 주는 역활을 합니다. 
17.검증 세트의 목적은 무엇인가요?
   A : 훈련세트 / 테스트 세트 / 검증 세트의 구별을 쉽게 하지는 못하겠네요. 전체 테스트 세트는 훈련 세트와 테스트 세트로 나눌 수 있고, 
       테스트 세트에 대한 분량의 검증이 중요함. 하지만 검증 세트는 최상의 성능을 내는 모데롸 하이퍼 파라미터를 선택하는 기위한 것이라고 하는 데.. 
       느낌이나 이해가 잘 되지는 않음 - 모델을 검증 하기 위해 테스트 세트 
18.테스트 세트를 사용해 하이퍼파라미터를 튜닝하면 어떤 문제가 생기나요?
   A : 일반화 오차를 테스트 세트에서 여러 번 측정 했으므로 모델과 하이퍼파라미터에 최적화된 모델을 만들기 때문에 새로운 데이터에 잘 작동 하지 
   않을 수 있슴.
19.교차 검증이 무엇이고, 왜 하나의 검증 세트보다 선호 하나요?
   훈련 데이터에서 검증 세트로 너무 많은 양의 데이터를 뺏기지 않기 위해 굦차 검증(cross-validation) 기법을 사용합니다. 훈련 세트를 여러 
   서브셋(subset) 으로 나누고 각 모델을 이 서브셋의 조합으로 훈련 시키고 나머지 부분으로 검증을 합니다. 모델과 하이퍼파라미터가 선택 되면 
   전체 훈련 데이터를 사용하여 선택한 하이퍼파라미터로 최종 모델을 훈련 시키고 테스트 세트에서 일반화 오차를 측정합니다.
       
Chapter 2 Q&A
1. 서포트 벡터 머신 회귀 (sklearn.svm.SVR)를 kernel="linear"(하이퍼파라미터 C를 바꿔가며)나 kernel="rbf"(하이퍼파라미터 C와 gamma 를 
바꿔가며)등의 다양한 하이퍼파라미터 설정으로 시도해 보세요. 지금은 이 하이퍼파라미터가 무엇을 의미하는지 너무 신경쓰지 마세요. 최상의 SVR 
모델은 무엇인가요?
2. gridSearchCV를 RandomizedSearchCV로 바꿔보세요.
3. 가장 중용한 특성을 선택하는 변환기를 준비 파이프라인으로 만들어 보세요.
4. 전체 데이터 준비 과정과 최종 예측을 하나의 파이프라인으로 만들어 보세요.
5. GridSearchCV를 사용해 준비 단계의 옵션을 자동으로 탐색해보세요.
